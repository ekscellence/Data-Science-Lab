
The Applied Data Science Lab, offered by WorldQuant University, is an immersive online program designed to equip students with practical skills in addressing real-world, intricate challenges. Spanning over 16 weeks, the program engages participants in a series of comprehensive data science projects that enable them to develop proficiency in data wrangling, analysis, model-building and effective communication through hands-on experience.

Throughout the program, I had the opportunity to actively participate in eight fascinating projects, all designed to strengthen fundamental data science concepts. Let me offer a concise explanation of each project.

- 010-housing-in-mexico
Analyzed a dataset comprising 21,000 properties to ascertain whether real estate prices are predominantly influenced by property size or location. The process involved importing and cleaning data from a CSV file, creating data visualizations and exploring the correlation between the two variables.

- 020-housing-in-buenos-aires
Developed a linear regression model aimed at predicting apartment prices in Argentina. Established a data pipeline to handle missing values and encode categorical features, subsequently enhancing model performance through the reduction of overfitting.
- 030-air-quality-in-nairobi
Built an ARMA time-series model for forecasting particulate matter levels in Kenya. Extracted data from a MongoDB database using pymongo and fine-tuned model performance through hyperparameter adjustments.
- 040-earthquake-damage-in-nepal
Constructed logistic regression and decision tree models for predicting earthquake damage to buildings. Extracted relevant data from a SQLite database and identified biases within the dataset that may contribute to discriminatory outcomes.
- 050-bankruptcy-in-poland
Developed random forest and gradient boosting models for predicting the likelihood of a company going bankrupt. Navigated the Linux command line, addressed data imbalance through resampling techniques and evaluated the impact of performance metrics such as precision and recall.
- 060-consumer-finances in-usa
Constructed a k-means model to cluster US consumers into distinct groups, employed principal component analysis (PCA) for data visualization and finally designed an interactive dashboard using Plotly Dash.
- 070-ds-admissions-in-wqu
Performed a chi-square test to assess the impact of email communication on program enrollment at WQU. Developed custom Python classes for an Extract, Transform, Load (ETL) process and designed an interactive data application following a three-tiered design pattern.
- 080-market-forecasting-in-india

Developed a GARCH time series model to forecast asset volatility, retrieved stock data via an API, cleaned and stored the data in a SQLite database and lastly constructed an API to deliver model predictions.


https://www.credly.com/badges/a213fe75-e6e0-4ee5-aba7-2eb49657eb5f







